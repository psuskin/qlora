Dies ist die Beschreibung des Moduls "metamodl" mit dem Namen "Meta Model": Classix besitzt durch seine Geschäftsmodellklassen und Datenfelder kein starres Model, somit auch auch keine zentrale Verwaltung der Entitäten und Datenfelder. Um dennoch die im System dynamisch erstellten Objekte, deren Attribute und Beziehungen beschreiben zu können, ist mit diesem Modul ein ObjectCrawler implementiert, der eigenständig die Datenbank durchwandert, Objekte aufsammelt, untersucht, kategorisiert und diese Informationen als Meta-Beschreibung hinterlegt.Diese Meta-Beschreibungen der Objekte und derer Attribute und Beziehungen können dann hier gepflegt werden.Bevor man die Suche startet, muss man die Einstellungen für die Suche festlegen, von denen die Geschwindigkeit und die Dauer der Suche abhängt. Die folgenden Einstellungen sind möglich:Unter den Randbedingungen kann man das maximale Alter der Meta-Infos angeben. Um die Suche zu beschleunigen, werden Meta-Informationen nicht überschrieben und übersprungen, falls sie jünger als das eingestellte Datum sind. Mit Transaktionssplitting gibt man an, nach wie vielen Tranaktionen (Analysen von Meta-Objekten) die Ergebnisse in der Datenbank gespeichert werden. Die maximale Collection-Tiefe gibt an, wie viele Elemente einer M1-, MN-Relation, oder Collection analysiert werden (bei 0 werden alle Elemente einer Collection durchsucht). Die maximale Collection-Tiefe kann die Dauer des Crawling-Vorgangs erheblich beieinflussen, ein Wert von 500, und 5 bei sehr großen Datenbanken, kann dazu führen, schnelle Ergebnisse zu bekommen. Ebenso maßgeblich für die Dauer des Crawlings ist der Parameter Rekursionstiefe (-1 steht für unendliche Tiefe). Die Rekursionstiefe bestimmt, wie weit der Crawler die Referenzen eines Objektes rekursiv untersuchen sollte. Unabhängig von dieser Einstellung führt der ObjectCrawler immer eine Breitensuche aus, d.h. referenzierte Objekte werden erst dann untersucht, nachdem alle Siblings eines Objektes untersucht wurden. Die letzte und wichtigste Option ist der REP-Startindex und dieser besagt, wo sich der Objektcrawler beim Durchsuchen der Datenbank befindet. Der Crawler durchsucht die Datenbank so, dass er von jeder REP ein einzelnes Objekt nimmt und untersucht, damit so schnell wie möglich ein übersichtliches und aussagekräftiges Bild der Datenbank entsteht. Dieser sogenannte REP-Startindex bestimmt den aktuellen (Start)index dieser Objektenentnahme aus den REPs. -1 lässt den Crawler ein zufälliges Element aus jeder REP zu entnehmen, möchte man jedoch einen vollständigen Scan durchführen, so sollte man bei 0 anfangen und die Inkrementierung dieses Wertes beobachten, um zu wissen, wo sich der Crawler im jeweiligen Moment befindet. Wenn dieser Wert die höchste Länge einer REP übersteigt, wird der Crawler automatisch beendet und man hat somit die ganzen REPs untersucht. Unter den Laufzeit-Optionen kann man die Crawling-Dauer des Objektcrawlers einschränken. Standardmäßig lässt man den Crawler laufen, bis man ihn stoppt (der Abbrechbutton im Progressbar-Fenster schließt die Suche mit EndTXN ab und somit ist der Button eher ein Stop-Button als ein Abbrech-Button) oder bis er fertig ist. Man kann den Crawler automatisch nach dem ersten Durchlauf beenden, indem man die gleichnamige Option auswählt, oder erst dann, wenn die Warteschlange mit allen REP-Objekten aus dem ersten Durchlauf samt ihren referenzierten Objekten abgearbeitet und leer ist, indem man die entsprechende Option Crawler beenden, wenn Queue leer ist auswählt.Je nach ausgewählter Option kann man das Verhalten bei Fehlern steuern. Fehler sind in diesem Sinne keine InstantView-Fehler, sondern logische Konsistenz-Fehler in der Datenbank. Es empfiehlt sich, die Option Fehler loggen und weiter machen auszuwählen.Unter sonstigen Einstellungen kann man diverse Optionen festlegen wie:ObjectCrawler loggen: alle Operationen des ObjectCrawlers werden in separate Log-Dateien geschrieben. Rückreferenzen intelligent verarbeiten: wenn diese Option ausgewählt ist, werden beim Untersuchen von Rückreferenzen gewisse Klassenüberprüfungen durchgeführt, die Fehlern vorbeugen. Dies ist die Beschreibung der Funktionalität des Moduls "metamodl" mit dem Namen "Meta Model" bezüglich ObjectCrawler: In diesem Fenster werden dem ObjectCrawler die Parameter zum Durchwandern der Datenbank mitgegeben.