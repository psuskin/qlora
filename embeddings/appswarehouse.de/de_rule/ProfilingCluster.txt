Dies ist die Beschreibung des Moduls "ProfilingCluster" mit dem Namen "Profiling - Clusteranalyse": Beispiel eines XML-Exports Hinweise Über ein Tool kann das Log eines Profiling-Laufes geclustert werden. Dazu ist Profiling.bat zu starten (in //iv/main/Inst/Profiling). Voraussetzung ist ein installiertes Java 1.4.Das Tool fragt nach dem Dateinamen mit dem Profiling-Log und beginnt anschließend mit der Analyse. Am Ende wird der Lauf mit einer Meldung quittiert. Das Ergebnis wird in einer HTML-Datei abgelegt, die z.B. mit Excel weiter verarbeitet werden kann. Dies ist die Beschreibung der Funktionalität des Moduls "ProfilingCluster" mit dem Namen "Profiling - Clusteranalyse" bezüglich Beispiel eines XML-Exports: Hier sind alle Makros aufgeführt, die während des Profilings aufgerufen wurden. Die Zahl vor dem Namen gibt den Level an: 1 bedeutet, dass das Makro (hier) direkt von der ListView aus aufgerufen wurde; 2 bedeutet, dass das Makro von einem anderen Makro aufgerufen wurde. Im obigen Beispiel wird ItemQuantity mit Level 1 und Level 3 aufgeführt, d.h. das Makro wird an zwei Stellen aufgerufen. Zusätzlich werden alle Datenbankaktivitäten unter 'database' zusammengefasst. In der Spalte 'Anzahl' ist angegeben, wie oft das Makro insgesamt aufgerufen wurde. In 'Gesamt' ist die Zeit in Millisekunden angegeben, die das Makro insgesamt verbraucht hat. 'Durchschnitt' schließlich ist das Ergebnis der Division 'Gesamtzeit' / 'Anzahl'. Hinweise Die Zeit, die für ein Makro gemessen wird, ist immer inklusive der Zeit für die Datenbank und die aufgerufenen Makros. Wenn z.B. ein Makro A 5ms braucht und ein Makro B aufruft, das 2ms braucht, dann stecken die 2ms von B bereits in den 5ms von A drin! Es wäre also falsch, einfach alle Zeiten in der Statistik zu addieren. 'database' ist daher nur für vergleichende Zwecke geeignet, um zu sehen, wie viel Zeit anteilig von der Datenbank verbraucht werden. Das obige Beispiel stammt aus einem XML-Export. Für die Auswertung wurden nur die Makros der ersten Ebene berücksichtigt. Dort drin enthalten sind bereits die Zeiten der anderen Makros und die Aufwände für die Datenbank. Die Zeiten der einzelnen Makros wurden nun zur Gesamtzeit in Relation gesetzt. Die Makros, die besonders viel Zeit in Anspruch nahmen, wurden optimiert.